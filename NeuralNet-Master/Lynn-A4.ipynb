{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Solution to the Towers of Hanoi Puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Lynn\n",
    "\n",
    "For this assignment, you will use reinforcement learning to solve the [Towers of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi) puzzle.  \n",
    "\n",
    "To accomplish this, you must modify the code discussed in lecture for learning to play Tic-Tac-Toe.  Modify the code  so that it learns to solve the three-disk, three-peg\n",
    "Towers of Hanoi Puzzle.  In some ways, this will be simpler than the\n",
    "Tic-Tac-Toe code.  \n",
    "\n",
    "Steps required to do this include the following:\n",
    "\n",
    "  - Represent the state, and use it as a tuple as a key to the Q dictionary.\n",
    "  - Make sure only valid moves are tried from each state.\n",
    "  - Assign reinforcement of $1$ to each move, even for the move that results in the goal state.\n",
    "\n",
    "Make a plot of the number of steps required to reach the goal for each\n",
    "trial.  Each trial starts from the same initial state.  Decay epsilon\n",
    "as in the Tic-Tac-Toe code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, how should we represent the state of this puzzle?  We need to keep track of which disks are on which pegs. Name the disks 1, 2, and 3, with 1 being the smallest disk and 3 being the largest. The set of disks on a peg can be represented as a list of integers.  Then the state can be a list of three lists.\n",
    "\n",
    "For example, the starting state with all disks being on the left peg would be `[[1, 2, 3], [], []]`.  After moving disk 1 to peg 2, we have `[[2, 3], [1], []]`.\n",
    "\n",
    "To represent that move we just made, we can use a list of two peg numbers, like `[1, 2]`, representing a move of the top disk on peg 1 to peg 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to some functions. Define at least the following functions. Examples showing required output appear below.\n",
    "\n",
    "   - `printState(state)`: prints the state in the form shown below\n",
    "   - `validMoves(state)`: returns list of moves that are valid from `state`\n",
    "   - `makeMove(state, move)`: returns new (copy of) state after move has been applied.\n",
    "   - `trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF)`: train the Q function for number of repetitions, decaying epsilon at start of each repetition. Returns Q and list or array of number of steps to reach goal for each repetition.\n",
    "   - `testQ(Q, maxSteps, validMovesF, makeMoveF)`: without updating Q, use Q to find greedy action each step until goal is found. Return path of states.\n",
    "\n",
    "A function that you might choose to implement is\n",
    "\n",
    "   - `stateMoveTuple(state, move)`: returns tuple of state and move.  \n",
    "    \n",
    "This is useful for converting state and move to a key to be used for the Q dictionary.\n",
    "\n",
    "Show the code and results for testing each function.  Then experiment with various values of `nRepetitions`, `learningRate`, and `epsilonDecayFactor` to find values that work reasonably well, meaning that eventually the minimum solution path of seven steps is found consistently.\n",
    "\n",
    "Make a plot of the number of steps in the solution path versus number of repetitions. The plot should clearly show the number of steps in the solution path eventually reaching the minimum of seven steps, though the decrease will not be monotonic.  Also plot a horizontal, dashed line at 7 to show the optimal path length.\n",
    "\n",
    "Add markdown cells in which you describe the Q learning algorithm and your implementation of Q learning as applied to the Towers of Hanoi problem.  Use at least 15 sentences, in one or more markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def printState(myState):\n",
    "    rowOne = 0\n",
    "    rowTwo = 0\n",
    "    rowThree = 0\n",
    "    colOne = 0\n",
    "    colTwo = 1\n",
    "    colThree = 2\n",
    "    # interate through 3x3 matrix\n",
    "    for i in range(3,0,-1):\n",
    "        temp = []\n",
    "        if len(myState[colOne]) >= i and len(myState[colOne]) > 0:           \n",
    "            print(myState[colOne][rowOne], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            rowOne += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")\n",
    "        if len(myState[colTwo]) >= i and len(myState[colTwo]) > 0:\n",
    "            print(myState[colTwo][rowTwo], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            rowTwo += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")\n",
    "        if len(myState[colThree]) >= i and len(myState[colThree]) > 0:\n",
    "            print(myState[colThree][rowThree], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            rowThree += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")\n",
    "        print()\n",
    "    print(\"------\")\n",
    "    \n",
    "def stateMoveTuple(myState, myMove):\n",
    "    colOne = tuple(myState[0])\n",
    "  #  print(colOne);\n",
    "    colTwo = tuple(myState[1])\n",
    "  #  print(colTwo);\n",
    "    colthree = tuple(myState[2])\n",
    "  #  print(colthree);\n",
    "    return ((colOne,colTwo,colthree), tuple(myMove))\n",
    "\n",
    "def makeMove(myState, myMove):\n",
    "    # offset disk and tower (1,2) to (0-1)  3x3 matrix\n",
    "\n",
    "    offSetDisc = myMove[0]-1\n",
    "    offSetTower = myMove[1]-1\n",
    "\n",
    "    targetDisc = myState[offSetDisc][0]\n",
    "    targetTower = offSetTower\n",
    "    \n",
    "    # remove targetDisc \n",
    "    myState[offSetDisc] = myState[offSetDisc][1:]\n",
    "    \n",
    "    #insert targetDisc into targetTower\n",
    "    myState[targetTower].insert(0, targetDisc)\n",
    "    return myState\n",
    "\n",
    "def validMoves(myState):\n",
    "    t = 4;\n",
    "    #tower 1 state \n",
    "    colOne = myState[0]\n",
    "    #tower 2 state \n",
    "    colTwo = myState[1]\n",
    "    #tower 3 state \n",
    "    colThree = myState[2]\n",
    "\n",
    "    myMoves = []\n",
    "    \n",
    "    topDiskTower1 = t\n",
    "    \n",
    "    topDiskTower2 = t\n",
    "    \n",
    "    topDiskTower3 = t\n",
    "\n",
    "    # grab top disk is tower is not empty\n",
    "    if len(colOne) > 0:\n",
    "        topDiskTower1 = colOne[0]\n",
    "        #print(topDiskTower1)\n",
    "    if len(colTwo) > 0:\n",
    "        topDiskTower2 = colTwo[0]\n",
    "       # print(topDiskTower2)\n",
    "    if len(colThree) > 0:\n",
    "        topDiskTower3 = colThree[0]\n",
    "       # print(topDiskTower3)\n",
    "\n",
    "    if topDiskTower1 < topDiskTower2:\n",
    "        myMoves.append([1,2])\n",
    "    if topDiskTower1 < topDiskTower3:\n",
    "        myMoves.append([1,3])\n",
    "    if topDiskTower2 < topDiskTower1:\n",
    "        myMoves.append([2,1])\n",
    "    if topDiskTower2 < topDiskTower3:\n",
    "        myMoves.append([2,3])\n",
    "    if topDiskTower3 < topDiskTower1:\n",
    "        myMoves.append([3,1])\n",
    "    if topDiskTower3 < topDiskTower2:\n",
    "        myMoves.append([3,2])\n",
    "\n",
    "    return myMoves\n",
    "\n",
    "def epsilonGreedy(epsilon, Q, myState):\n",
    "    myMoves = validMoves(myState)\n",
    "    #print(\"mymoves \", myMoves)\n",
    "    # generate random uniform default interval 0-1 floating points\n",
    "    randomMove = np.random.uniform()\n",
    "    if randomMove < epsilon:\n",
    "        #print(\"explore \", myMoves[ np.random.choice(len(myMoves))])\n",
    "        # return random number based on elements in target tower\n",
    "        # explore a bit\n",
    "        return myMoves[ np.random.choice(len(myMoves))]\n",
    "    else:\n",
    "        #print(\"move greedy Q\", Q)\n",
    "        # exploit what we already know\n",
    "        Qs = np.array([Q.get(stateMoveTuple(myState, m), 1) for m in myMoves])\n",
    "        return myMoves[ np.argmax(Qs) ]\n",
    "\n",
    "def trainQ(trainCount, learningRate, DecayRate, validMovesF, makeEpsilonMove):\n",
    "    Q = {}\n",
    "    myEpsilon = 1.0\n",
    "    steps = []\n",
    "\n",
    "    for num in range(trainCount):\n",
    "        myEpsilon *= DecayRate\n",
    "        #print(\"decay \", myEpsilon)\n",
    "        myStepCount = 0\n",
    "        myState = [[1,2,3],[],[]]\n",
    "        oldmove = []\n",
    "        myOldstate = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            myStepCount += 1\n",
    "\n",
    "            # return explore or exploit move\n",
    "            epsilionMove = epsilonGreedy(myEpsilon, Q, myState)\n",
    "            #print(\"eplsion return \", epsilionMove)\n",
    "            stateNew = []\n",
    "            stateNew.append(copy.copy(myState[0]))\n",
    "            stateNew.append(copy.copy(myState[1]))\n",
    "            stateNew.append(copy.copy(myState[2]))\n",
    "\n",
    "            stateNew = makeEpsilonMove(stateNew, epsilionMove)\n",
    "\n",
    "            if stateMoveTuple(myState, epsilionMove) not in Q:\n",
    "                # add new state and assoicated move to Q and init to 1\n",
    "                #print(\"new state \", stateMoveTuple(myState, epsilionMove) )\n",
    "                Q[stateMoveTuple(myState, epsilionMove)] = 1\n",
    "            else:\n",
    "                if myStepCount > 1:\n",
    "                    oldStateTuple = stateMoveTuple(myOldstate, oldmove)\n",
    "                    #print(\"this state already exist \", oldStateTuple, \"learning \", Q[oldStateTuple])\n",
    "                    Q[oldStateTuple] += learningRate * (-1 + Q[stateMoveTuple(myState, epsilionMove)] - Q[oldStateTuple])\n",
    "            myOldstate, oldmove = myState, epsilionMove\n",
    "            myState = stateNew\n",
    "            if myState == [[],[],[1,2,3]]:\n",
    "                done = True\n",
    "                Q[stateMoveTuple(myState,epsilionMove)] = -1\n",
    "\n",
    "        steps.append(myStepCount)\n",
    "    return Q, steps\n",
    "\n",
    "def testQ(Q, myMaxSteps, pewteeweet, myMakeMove):\n",
    "    myState = [[1,2,3],[],[]]\n",
    "    allStates = []\n",
    "    for i in range(myMaxSteps):\n",
    "        myMove = greedy(Q, myState)\n",
    "        stateNew = []\n",
    "        stateNew.append(copy.copy(myState[0]))\n",
    "        stateNew.append(copy.copy(myState[1]))\n",
    "        stateNew.append(copy.copy(myState[2]))\n",
    "        stateNew = myMakeMove(stateNew, myMove)\n",
    "        if myState == [[],[],[1,2,3]]:\n",
    "            break\n",
    "        allStates.append(stateNew)\n",
    "        myState = stateNew\n",
    "    return allStates\n",
    "\n",
    "def greedy(Q, myState):\n",
    "    myMoves = validMoves(myState)\n",
    "    myQs = np.array([Q.get(stateMoveTuple(myState, m), 1) for m in myMoves])\n",
    "    return myMoves[ np.argmax(myQs) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "describe the trainQ and testQ functions. Q based learning uses a Numerical based reward, we attach a value reward to each step.  We map trasitions between states with a reward. Everytime we get a duplicate state the learning varible is updated. Setting the epsilion to a high or lower number increases or decreseses the amount of exploing and exploiting that happens during the trainQ phase. TestQ uses the Q table produced and takes the greedy approch to get optimal solution 2^n − 1.  We can represented as a graph, kinda like a shortest path algorthm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   \n",
      "2   \n",
      "3   \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "state = [[1, 2, 3], [], []]\n",
    "printState(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 2, 3), (), ()), (1, 2))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move =[1, 2]\n",
    "\n",
    "stateMoveTuple(state, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [1], []]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newstate = makeMove(state, move)\n",
    "newstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "2   \n",
      "3 1  \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "printState(newstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ(50, 0.5, 0.7, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85,\n",
       " 78,\n",
       " 147,\n",
       " 29,\n",
       " 37,\n",
       " 16,\n",
       " 7,\n",
       " 14,\n",
       " 41,\n",
       " 11,\n",
       " 8,\n",
       " 13,\n",
       " 33,\n",
       " 21,\n",
       " 17,\n",
       " 10,\n",
       " 12,\n",
       " 42,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 25,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = testQ(Q, 20, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2, 3], [], [1]],\n",
       " [[3], [2], [1]],\n",
       " [[3], [1, 2], []],\n",
       " [[], [1, 2], [3]],\n",
       " [[1], [2], [3]],\n",
       " [[1], [], [2, 3]],\n",
       " [[], [], [1, 2, 3]]]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "2   \n",
      "3  1 \n",
      "------\n",
      "\n",
      "   \n",
      "   \n",
      "3 2 1 \n",
      "------\n",
      "\n",
      "   \n",
      " 1  \n",
      "3 2  \n",
      "------\n",
      "\n",
      "   \n",
      " 1  \n",
      " 2 3 \n",
      "------\n",
      "\n",
      "   \n",
      "   \n",
      "1 2 3 \n",
      "------\n",
      "\n",
      "   \n",
      "  2 \n",
      "1  3 \n",
      "------\n",
      "\n",
      "  1 \n",
      "  2 \n",
      "  3 \n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    printState(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Download and extract `A4grader.py` from [A4grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A4grader.tar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Lynn-A4.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing validMoves([[1], [2], [3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing validMoves([[], [], [1, 2, 3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[3, 1], [3, 2]]\n",
      "\n",
      "Testing makeMove([[], [], [1, 2, 3]], [3, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [1], [2, 3]]\n",
      "\n",
      "Testing makeMove([[2], [3], [1]], [1, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [2, 3], [1]]\n",
      "\n",
      "Testing   Q, steps = trainQ(1000, 0.5, 0.7, validMoves, makeMove).\n",
      "\n",
      "--- 10/10 points. Q dictionary has correct number of entries.\n",
      "\n",
      "--- 10/10 points. The mean of the number of steps of 7.506 is correctly < 10.\n",
      "\n",
      "Testing   path = testQ(Q, 20, validMoves, makeMove).\n",
      "\n",
      "--- 20/20 points. Correctly returns path of length 7, which is correctly less than 10.\n",
      "\n",
      "C:\\Users\\hailviral1\\Desktop\\cs440 Execution Grade is 80 / 80\n",
      "\n",
      " Remaining 20 points will be based on your text describing the trainQ and testQ functions.\n",
      "\n",
      "C:\\Users\\hailviral1\\Desktop\\cs440 FINAL GRADE is   / 100\n",
      "\n",
      "C:\\Users\\hailviral1\\Desktop\\cs440 EXTRA CREDIT is   / 1\n"
     ]
    }
   ],
   "source": [
    "%run -i A5grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your code to solve the Towers of Hanoi puzzle with 4 disks instead of 3.  Name your functions\n",
    "\n",
    "    - printState_4disk\n",
    "    - validMoves_4disk\n",
    "    - makeMove_4disk\n",
    "\n",
    "Find values for number of repetitions, learning rate, and epsilon decay factor for which trainQ learns a Q function that testQ can use to find the shortest solution path.  Include the output from the successful calls to trainQ and testQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
